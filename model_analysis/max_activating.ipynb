{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Imports-and-Constants\" data-toc-modified-id=\"Imports-and-Constants-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Imports and Constants</a></span></li><li><span><a href=\"#Helper-Functions\" data-toc-modified-id=\"Helper-Functions-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Helper Functions</a></span></li><li><span><a href=\"#NL\" data-toc-modified-id=\"NL-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>NL</a></span></li><li><span><a href=\"#MS\" data-toc-modified-id=\"MS-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>MS</a></span></li><li><span><a href=\"#Create-activation-maps-figure\" data-toc-modified-id=\"Create-activation-maps-figure-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Create activation maps figure</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import heapq\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "\n",
    "sys.path.append('../')\n",
    "from batchers import batcher, dataset_constants\n",
    "from models.resnet_model import Hyperspectral_Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CKPTS_DIR = '../ckpts'\n",
    "LOGS_DIR = '../logs'\n",
    "NUM_TOP_IMGS = 8\n",
    "\n",
    "MODEL_PATHS = {\n",
    "    'incountry_resnet_ms_D': [\n",
    "        'DHSIncountry/incountryD_18preact_ms_samescaled_b64_fc001_conv001_lr0001',\n",
    "        'ckpt-40'],\n",
    "    'incountry_resnet_nl_C': [\n",
    "        'DHSIncountry/incountryC_18preact_nl_random_b64_fc1.0_conv1.0_lr0001',\n",
    "        'ckpt-145']\n",
    "}\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "LABEL_NAME = 'wealthpooled'\n",
    "GPU = 0\n",
    "GPU_USAGE = 0.9\n",
    "IS_TRAINING = False\n",
    "MODEL_PARAMS = {\n",
    "    'fc_reg': 5e-3,\n",
    "    'conv_reg': 5e-3,\n",
    "    'num_layers': 18,\n",
    "    'num_outputs': 1\n",
    "}\n",
    "\n",
    "TENSOR_NAMES = {\n",
    "    'scale1_img': 'resnet/scale1/scale1_img:0',  # batch_size, 112, 112,  64\n",
    "    'scale2_img': 'resnet/scale2/scale2_img:0',  # batch_size,  56,  56,  64\n",
    "    'scale3_img': 'resnet/scale3/scale3_img:0',  # batch_size,  28,  28, 128\n",
    "    'scale4_img': 'resnet/scale4/scale4_img:0',  # batch_size,  14,  14, 256\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dhs_test_batcher(ls_bands, nl_band):\n",
    "    '''\n",
    "    Args\n",
    "    - ls_bands: one of ['rgb', 'ms', None]\n",
    "    - nl_band: one of ['merge', 'split', None]\n",
    "    - fold: str, one of ['A', 'B', 'C', 'D', 'E']\n",
    "\n",
    "    Returns\n",
    "    - batcher: Batcher\n",
    "    '''\n",
    "    all_tfrecord_paths = np.asarray(batcher.get_tfrecord_paths('2009-17', 'all'))\n",
    "    assert len(all_tfrecord_paths) == dataset_constants.SIZES['2009-17']['all']\n",
    "\n",
    "    b = batcher.Batcher(\n",
    "        tfrecord_files=all_tfrecord_paths,\n",
    "        dataset='2009-17',\n",
    "        batch_size=BATCH_SIZE,\n",
    "        label_name=LABEL_NAME,\n",
    "        num_threads=4,\n",
    "        epochs=1,\n",
    "        ls_bands=ls_bands,\n",
    "        nl_band=nl_band,\n",
    "        shuffle=False,\n",
    "        augment=False,\n",
    "        normalize=True,\n",
    "        cache=False)\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_heap(h, k, value, data):\n",
    "    '''\n",
    "    Heap h keeps track of the max k elements\n",
    "\n",
    "    We will actually use a min-heap for this task. That way, when a new element\n",
    "    comes in, we compare it to the smallest node in the heap, h[0]. If the new\n",
    "    value is greater than h[0], we pop h[0] and add the new element in.\n",
    "\n",
    "    Args\n",
    "    - h: list, either empty [] or already heapified\n",
    "    - k: desired capacity of the heap\n",
    "    - value: value to compare with\n",
    "    - data: data to store with the value\n",
    "    ''' \n",
    "    if len(h) < k:\n",
    "        heapq.heappush(h, (value, data))\n",
    "    else:\n",
    "        heapq.heappushpop(h, (value, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_batches(sess, tensors_dict_ops, tensor_name, max_nbatches=None, verbose=False):\n",
    "    '''Runs the ops in tensors_dict_ops for a fixed number of batches or until\n",
    "    reaching a tf.errors.OutOfRangeError, concatenating the runs.\n",
    "\n",
    "    Note: assumes that the dataset iterator doesn't need initialization, or is\n",
    "        already initialized.\n",
    "\n",
    "    Args\n",
    "    - sess: tf.Session\n",
    "    - tensors_dict_ops: dict, str => tf.Tensor, shape [batch_size] or [batch_size, D]\n",
    "    - max_nbatches: int, maximum number of batches to run the ops for,\n",
    "        set to None to run until reaching a tf.errors.OutOfRangeError\n",
    "\n",
    "    Returns\n",
    "    - top_images_avg: dict, maps filter number (int) into list of (value, data) tuples\n",
    "        value = (mean filter activation for a particular image, negative image index)\n",
    "        data = (img, year, loc, activation map)\n",
    "    '''\n",
    "    top_images_avg = defaultdict(list)\n",
    "\n",
    "    curr_batch = 0\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        while True:\n",
    "            all_tensors = sess.run(tensors_dict_ops)\n",
    "\n",
    "            imgs = all_tensors['images']  # N, H, W, C\n",
    "            years = all_tensors['years']\n",
    "            locs = all_tensors['locs']\n",
    "            actmaps = all_tensors[tensor_name]\n",
    "\n",
    "            batch_size, _, _, num_filters = actmaps.shape\n",
    "\n",
    "            actmaps_means = np.mean(actmaps, axis=(1, 2), dtype=np.float64)  # shape [batch_size, num_filters]\n",
    "\n",
    "            for i in range(batch_size):\n",
    "                img = imgs[i]\n",
    "                year = years[i]\n",
    "                loc = tuple(locs[i])\n",
    "                actmap = actmaps[i]  # shape [H, W, num_filters]\n",
    "                actmap_means = actmaps_means[i]  # shape [num_filters]\n",
    "\n",
    "                for f in range(num_filters):\n",
    "                    value = (actmap_means[f], -(i + curr_batch*BATCH_SIZE))\n",
    "                    data = (img, year, loc, actmap[:, :, f])\n",
    "                    add_to_heap(h=top_images_avg[f], k=NUM_TOP_IMGS, value=value, data=data)\n",
    "\n",
    "            curr_batch += 1\n",
    "            if verbose:\n",
    "                speed = curr_batch / (time.time() - start_time)\n",
    "                print(f'\\rRan {curr_batch} batches ({speed:.3f} batch/s)', end='')\n",
    "            if (max_nbatches is not None) and (curr_batch >= max_nbatches):\n",
    "                break\n",
    "            if curr_batch >= 15:\n",
    "                break\n",
    "\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        pass\n",
    "\n",
    "    print()  # print a newline, since the previous print()'s don't print newlines\n",
    "    return top_images_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_act_images(ckpt_path: str, fold: str, ls_bands: str,\n",
    "                       nl_band: str, tensor_name: str):\n",
    "    '''\n",
    "    Args\n",
    "    - ckpt_path: str\n",
    "    - fold: str, one of ['A', 'B', 'C', 'D', 'E']\n",
    "    - ls_bands: str or None\n",
    "    - nl_band: str or None\n",
    "    - tensor_name: str, key of TENSOR_NAMES\n",
    "\n",
    "    Returns\n",
    "    - top_images_avg: dict, maps filter number (int) into list of (value, data) tuples\n",
    "        value = (mean filter activation for a particular image, negative image index)\n",
    "        data = (img, year, loc, activation map)\n",
    "    '''\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    print('=== Running model ===')\n",
    "    print('- ckpt:', ckpt_path)\n",
    "    print('- fold:', fold)\n",
    "    print('- ls_bands, nl_band:', ls_bands, nl_band)\n",
    "\n",
    "    init_iter, batch_op = get_dhs_test_batcher(ls_bands, nl_band).get_batch()\n",
    "\n",
    "    print('Building model...')\n",
    "    model = Hyperspectral_Resnet(batch_op['images'], is_training=IS_TRAINING, **MODEL_PARAMS)\n",
    "\n",
    "    graph = tf.get_default_graph()\n",
    "    tensors_dict_ops = {\n",
    "        'images': batch_op['images'],\n",
    "        'years': batch_op['years'],\n",
    "        'locs': batch_op['locs'],\n",
    "        tensor_name: graph.get_tensor_by_name(TENSOR_NAMES[tensor_name])\n",
    "    }\n",
    "\n",
    "    print('Creating session...')\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = str(GPU)\n",
    "    config_proto = tf.ConfigProto()\n",
    "    config_proto.gpu_options.per_process_gpu_memory_fraction = GPU_USAGE\n",
    "\n",
    "    with tf.Session(config=config_proto) as sess:\n",
    "        sess.run(init_iter)\n",
    "\n",
    "        # clear the model weights, then load saved checkpoint\n",
    "        print('Loading saved ckpt...')\n",
    "        saver = tf.train.Saver(var_list=None)\n",
    "        sess.run([tf.global_variables_initializer(), tf.local_variables_initializer()])\n",
    "        saver.restore(sess, ckpt_path)\n",
    "\n",
    "        # run the saved model\n",
    "        top_images_avg = run_batches(sess, tensors_dict_ops, tensor_name, verbose=True)\n",
    "    return top_images_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_activations(imgs, actmaps, locs=None, years=None, title=None, size=4, nl=False, savedir=None):\n",
    "    '''\n",
    "    Args\n",
    "    - imgs: list of np.array, length N, each np.array has shape [H, W] or [H, W, 3]\n",
    "        - if [H, W, 3], then band order is assumed to be R, G, B\n",
    "    - actmaps: list of np.array, length N, each np.array has shape [actH, actW]\n",
    "    - locs: list of (lat, lon) tuples\n",
    "    - years: list of int\n",
    "    - title: str, figure title\n",
    "    - size: int, size of each img, in inches\n",
    "    - nl: bool, when plotting nightlights images\n",
    "    - savedir: str, path to directory to save imgs and activation maps\n",
    "    '''\n",
    "    nimgs = len(imgs)\n",
    "    assert len(actmaps) == nimgs\n",
    "\n",
    "    # make copy, so we don't modify the originals\n",
    "    np_imgs = np.array(imgs)\n",
    "    np_actmaps = np.abs(np.array(actmaps))  # activation maps aren't always after a ReLU\n",
    "\n",
    "    # sort images by mean activation in descending order\n",
    "    sorted_index = np.argsort(np.mean(np_actmaps, axis=(1, 2)))[::-1]\n",
    "    np_imgs = np_imgs[sorted_index]\n",
    "    np_actmaps = np_actmaps[sorted_index]\n",
    "\n",
    "    if locs is not None:\n",
    "        locs = np.array(locs)  # make copy\n",
    "        locs = locs[sorted_index]\n",
    "    if years is not None:\n",
    "        years = np.array(years)  # make copy\n",
    "        years = years[sorted_index]\n",
    "\n",
    "    max_act = np.percentile(np_actmaps, q=99)\n",
    "\n",
    "    fig, axs = plt.subplots(2, nimgs, figsize=[size*nimgs, size*2])\n",
    "\n",
    "    for i in range(nimgs):\n",
    "        img = np_imgs[i]\n",
    "        actmap = np_actmaps[i]\n",
    "\n",
    "        # center images towards mean-0\n",
    "        img = img / 6\n",
    "        mean = np.mean(img)\n",
    "        img -= np.sign(mean) * min(0.9*abs(mean), abs(mean)**1.4)\n",
    "        new_mean = np.mean(img)\n",
    "\n",
    "        # scale images towards std-dev 1/6\n",
    "        std = np.std(img)\n",
    "        img = (img - new_mean) * (0.16 / std)**0.7 + new_mean\n",
    "        print('Mean_0:', mean, 'Mean_new:', new_mean, 'Std_0:', std, 'Std_new:', np.std(img))\n",
    "\n",
    "        img = np.clip(img + 0.5, a_min=0, a_max=1)\n",
    "\n",
    "        if nl:\n",
    "            mean = np.mean(actmap)\n",
    "            std = np.std(actmap)\n",
    "            actmap_max = min(np.max(actmap), mean + 6 * std)\n",
    "            actmap_min = max(np.min(actmap), mean - 6 * std)\n",
    "            actmap = (actmap - actmap_min) / actmap_max\n",
    "            actmap = np.clip(actmap, a_min=0, a_max=1)\n",
    "        else:\n",
    "            actmap = np.clip(actmap, a_min=0, a_max=max_act) / max_act\n",
    "    \n",
    "        # origin='lower' to match lat/lon direction\n",
    "        axs[0, i].imshow(img, origin='lower', vmin=0, vmax=1)\n",
    "        axs[1, i].imshow(actmap, origin='lower', vmin=0, vmax=1,\n",
    "                         interpolation='none', cmap='gray')\n",
    "\n",
    "        axs[0, i].axis('off')\n",
    "        axs[1, i].axis('off')\n",
    "\n",
    "        ax_title = []\n",
    "        if locs is not None:\n",
    "            lat, lon = locs[i]\n",
    "            ax_title.append(f'loc: ({lat:.4f}, {lon:.4f})')\n",
    "        if years is not None:\n",
    "            year = years[i]\n",
    "            ax_title.append(f'year: {year}')\n",
    "        if len(ax_title) > 0:\n",
    "            ax_title = ' '.join(ax_title)\n",
    "            axs[0, i].set_title(ax_title)\n",
    "\n",
    "        if savedir is not None:\n",
    "            os.makedirs(savedir, exist_ok=True)\n",
    "            img_filename = os.path.join(savedir, f'img_{i}.png')\n",
    "            # plt.imsave(img_filename, img, vmin=0, vmax=1, format='png', origin='lower')\n",
    "            PIL.Image.fromarray((img * 255).astype(np.uint8)).transpose(PIL.Image.FLIP_TOP_BOTTOM).save(img_filename, optimize=True)\n",
    "\n",
    "            actmap_filename = os.path.join(savedir, f'actmap_{i}.png')\n",
    "            # plt.imsave(actmap_filename, actmap, vmin=0, vmax=1, format='png', origin='lower', cmap='gray')\n",
    "            PIL.Image.fromarray((actmap * 255).astype(np.uint8)).transpose(PIL.Image.FLIP_TOP_BOTTOM).save(actmap_filename, optimize=True)\n",
    "\n",
    "    if title is not None:\n",
    "        fig.suptitle(title, y=1.03)\n",
    "    fig.subplots_adjust(wspace=0, hspace=0)\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actmaps_pkl_path = 'dhs_incountryC_actmaps_nl.pkl'\n",
    "if not os.path.exists(actmaps_pkl_path):\n",
    "    ckpt_path = os.path.join(CKPTS_DIR, *MODEL_PATHS['incountry_resnet_nl_C'])\n",
    "    fold = 'C'\n",
    "    ls_bands = None\n",
    "    nl_band = 'split'\n",
    "    tensor_name = 'scale2_img'\n",
    "\n",
    "    top_images_avg_nl = get_max_act_images(ckpt_path, fold, ls_bands, nl_band, tensor_name)\n",
    "    with open(actmaps_pkl_path, 'wb') as f:\n",
    "        pickle.dump(top_images_avg_nl, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(actmaps_pkl_path, 'rb') as f:\n",
    "    top_images_avg_nl = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in range(len(top_images_avg_nl)):\n",
    "    imgs = []\n",
    "    locs = []\n",
    "    actmaps = []\n",
    "\n",
    "    for value, data in top_images_avg_nl[f]:\n",
    "        img, year, loc, actmap = data\n",
    "        C = 0 if year < 2012 else 1\n",
    "        img = img[:, :, C]\n",
    "        imgs.append(img)\n",
    "        locs.append(loc)\n",
    "        actmaps.append(actmap)\n",
    "\n",
    "    title = f'Filter {f}'\n",
    "    plot_activations(imgs, actmaps, locs=locs, title=title, size=2, nl=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actmaps_pkl_path = 'dhs_incountryD_actmaps_ms.pkl'\n",
    "if not os.path.exists(actmaps_pkl_path):\n",
    "    ckpt_path = os.path.join(CKPTS_DIR, *MODEL_PATHS['incountry_resnet_ms_D'])\n",
    "    fold = 'D'\n",
    "    ls_bands = 'ms'\n",
    "    nl_band = None\n",
    "    tensor_name = 'scale3_img'\n",
    "\n",
    "    top_images_avg_ms = get_max_act_images(ckpt_path, fold, ls_bands, nl_band, tensor_name)\n",
    "    with open(actmaps_pkl_path, 'wb') as f:\n",
    "        pickle.dump(top_images_avg_ms, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(actmaps_pkl_path, 'rb') as f:\n",
    "    top_images_avg_ms = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for f in sorted(top_images_avg_ms.keys()):\n",
    "#     imgs = []\n",
    "#     years = []\n",
    "#     locs = []\n",
    "#     actmaps = []\n",
    "\n",
    "#     for value, data in top_images_avg_ms[f]:\n",
    "#         img, year, loc, actmap = data\n",
    "#         img = img[:, :, [2, 1, 0]]  # convert from BGR to RGB\n",
    "#         imgs.append(img)\n",
    "#         years.append(year)\n",
    "#         locs.append(loc)\n",
    "#         actmaps.append(actmap)\n",
    "\n",
    "#     title = f'Filter {f}'\n",
    "#     plot_activations(imgs, actmaps, locs=locs, years=years, title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ms_filters_to_label = {\n",
    "    2: 'urban',\n",
    "    10: 'water',\n",
    "    20: 'orange',\n",
    "    45: 'water',\n",
    "    59: 'senegal_river',\n",
    "    64: 'farmland',\n",
    "    79: 'canyons',\n",
    "    82: 'greenery',\n",
    "    102: 'greenery',\n",
    "    105: 'orange'\n",
    "}\n",
    "\n",
    "for f in range(len(top_images_avg_ms)):\n",
    "    if f not in ms_filters_to_label:\n",
    "        continue\n",
    "\n",
    "    imgs = []\n",
    "    years = []\n",
    "    locs = []\n",
    "    actmaps = []\n",
    "\n",
    "    for value, data in top_images_avg_ms[f]:\n",
    "        img, year, loc, actmap = data\n",
    "        img = img[:, :, [2, 1, 0]]  # convert from BGR to RGB\n",
    "        imgs.append(img)\n",
    "        years.append(year)\n",
    "        locs.append(loc)\n",
    "        actmaps.append(actmap)\n",
    "\n",
    "    title = f'Filter {f:d}'\n",
    "    savedir = None\n",
    "    if f in ms_filters_to_label.keys():\n",
    "        savedir = os.path.join(LOGS_DIR, MODEL_PATHS['incountry_resnet_ms_D'][0], 'actmaps', str(f))\n",
    "    plot_activations(imgs, actmaps, locs=locs, title=title, savedir=savedir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create activation maps figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_grid(imgs, size, resize=PIL.Image.NEAREST, spacing=0, color=0):\n",
    "    '''\n",
    "    Args\n",
    "    - imgs: list of list of PIL.Image, 1 sublist for each row of images\n",
    "    - size: int, width/height in pixels to reshape images to\n",
    "    - resize: PIL filter\n",
    "    - spacing: int, number of pixels between adjacent images\n",
    "    - color: int, spacing color, 0 for black, 255 for white\n",
    "\n",
    "    Returns: np.array, grid of images\n",
    "    '''\n",
    "    nrows = len(imgs)\n",
    "    ncols = len(imgs[0])\n",
    "\n",
    "    gridH = nrows * size + (nrows - 1) * spacing\n",
    "    gridW = ncols * size + (ncols - 1) * spacing\n",
    "    grid = np.ones([gridH, gridW, 3], dtype=np.uint8) * color\n",
    "\n",
    "    for r in range(nrows):\n",
    "        for c in range(ncols):\n",
    "            img = imgs[r][c]\n",
    "            if img.size != (size, size):\n",
    "                img = img.resize((size, size), resize)\n",
    "            i = r * (size + spacing)\n",
    "            j = c * (size + spacing)\n",
    "            grid[i:i+size, j:j+size, :] = np.asarray(img).reshape(size, size, -1)\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in [2, 10, 64]:\n",
    "    savedir = os.path.join(LOGS_DIR, MODEL_PATHS['incountry_resnet_ms_D'][0], 'actmaps', str(f))\n",
    "    top_row, bot_row = [], []\n",
    "    for i in range(NUM_TOP_IMGS):\n",
    "        top_row.append(PIL.Image.open(os.path.join(savedir, f'img_{i}.png')))\n",
    "        bot_row.append(PIL.Image.open(os.path.join(savedir, f'actmap_{i}.png')))\n",
    "    imgs = [top_row, bot_row]\n",
    "    grid = images_grid(imgs, size=224, spacing=5, color=255)\n",
    "    savepath = os.path.join(savedir, 'grid.png')\n",
    "    PIL.Image.fromarray(grid).save(savepath, optimize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
